{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65c85050",
   "metadata": {},
   "source": [
    "## YOLO Dataset Conversion\n",
    "\n",
    "Creates the complete structure for YOLO11 with:\n",
    "- Properly structured directories (train/images, train/labels, etc.)\n",
    "- TIFF images (4 channels) with unique names\n",
    "- Annotations in YOLO format (.txt)\n",
    "- dataset.yaml file with channel configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b8b800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import yaml\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import tifffile\n",
    "\n",
    "BASE_DATA_DIR = Path(r\"./data/thermalnumpy\")\n",
    "TIFF_DATA_DIR = Path(r\"./data/tiff_4channel\")\n",
    "YOLO_OUTPUT_DIR = Path(r\"./data/thermal_yolo\")\n",
    "TRAIN_JSON = Path(r\"./data/Flug1_100-104Media_coco.json\")\n",
    "TEST_JSON = Path(r\"./data/Flug1_105Media_coco.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e07c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"YOLO DATASET CREATION - Complete Structure\")\n",
    "print(f\"\\nOutput directory: {YOLO_OUTPUT_DIR}\")\n",
    "print(f\"Image format: TIFF 4 channels (4, H, W)\")\n",
    "print(f\"Annotation format: YOLO txt (class x_center y_center width height - normalized)\")\n",
    "\n",
    "# Create YOLO directory structure\n",
    "train_images_dir = YOLO_OUTPUT_DIR / \"train\" / \"images\"\n",
    "train_labels_dir = YOLO_OUTPUT_DIR / \"train\" / \"labels\"\n",
    "val_images_dir = YOLO_OUTPUT_DIR / \"val\" / \"images\"\n",
    "val_labels_dir = YOLO_OUTPUT_DIR / \"val\" / \"labels\"\n",
    "\n",
    "for dir_path in [train_images_dir, train_labels_dir, val_images_dir, val_labels_dir]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nDirectory structure created:\")\n",
    "print(f\"   {train_images_dir}\")\n",
    "print(f\"   {train_labels_dir}\")\n",
    "print(f\"   {val_images_dir}\")\n",
    "print(f\"   {val_labels_dir}\")\n",
    "\n",
    "def convert_coco_to_yolo_bbox(coco_bbox, img_width, img_height):\n",
    "    \"\"\"\n",
    "    Convert COCO bbox [x, y, width, height] to YOLO format [x_center, y_center, width, height] normalized\n",
    "    \"\"\"\n",
    "    x, y, w, h = coco_bbox\n",
    "    x_center = x + w / 2\n",
    "    y_center = y + h / 2\n",
    "    x_center_norm = x_center / img_width\n",
    "    y_center_norm = y_center / img_height\n",
    "    w_norm = w / img_width\n",
    "    h_norm = h / img_height\n",
    "    return x_center_norm, y_center_norm, w_norm, h_norm\n",
    "\n",
    "def convert_coco_segmentation_to_yolo(segmentation, img_width, img_height):\n",
    "    \"\"\"\n",
    "    Convert COCO segmentation to YOLO format (normalized points)\n",
    "    \"\"\"\n",
    "    if not segmentation or len(segmentation) == 0:\n",
    "        return None\n",
    "    polygon = segmentation[0] if isinstance(segmentation[0], list) else segmentation\n",
    "    normalized_points = []\n",
    "    for i in range(0, len(polygon), 2):\n",
    "        x = polygon[i] / img_width\n",
    "        y = polygon[i + 1] / img_height\n",
    "        normalized_points.extend([x, y])\n",
    "    return normalized_points\n",
    "\n",
    "def process_yolo_split(input_dir, output_images_dir, output_labels_dir, json_path, split_name, category_mapping):\n",
    "    \"\"\"\n",
    "    Process a split (train/val) for YOLO:\n",
    "    - Copy/convert images with unique names (no subfolders)\n",
    "    - Create .txt files with YOLO annotations\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing {split_name.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"JSON: {json_path}\")\n",
    "    if not json_path.exists():\n",
    "        print(f\"File not found: {json_path}\")\n",
    "        return 0, 0\n",
    "    with open(json_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "    images_info = {img['id']: img for img in coco_data.get('images', [])}\n",
    "    annotations = coco_data.get('annotations', [])\n",
    "    print(f\"JSON stats:\")\n",
    "    print(f\"   Images: {len(images_info)}\")\n",
    "    print(f\"   Annotations: {len(annotations)}\")\n",
    "    annotations_by_image = {}\n",
    "    for ann in annotations:\n",
    "        img_id = ann['image_id']\n",
    "        if img_id not in annotations_by_image:\n",
    "            annotations_by_image[img_id] = []\n",
    "        annotations_by_image[img_id].append(ann)\n",
    "    success_count = 0\n",
    "    error_count = 0\n",
    "    for img_id, img_info in tqdm(images_info.items(), desc=f\"Converting {split_name}\"):\n",
    "        try:\n",
    "            file_name = img_info['file_name']\n",
    "            img_width = img_info['width']\n",
    "            img_height = img_info['height']\n",
    "            unique_name = file_name.replace('/', '_').replace('\\\\', '_').replace('.npy', '.tiff')\n",
    "            source_tiff = input_dir / file_name.replace('.npy', '.tiff')\n",
    "            if not source_tiff.exists():\n",
    "                source_numpy = BASE_DATA_DIR / split_name / \"images\" / file_name\n",
    "                if source_numpy.exists():\n",
    "                    print(f\"\\nTIFF not found, converting from numpy: {file_name}\")\n",
    "                    data = np.load(source_numpy)\n",
    "                    data_4ch = data[:, :, :4]\n",
    "                    data_transposed = np.transpose(data_4ch, (2, 0, 1))\n",
    "                    dest_image = output_images_dir / unique_name\n",
    "                    try:\n",
    "                        import tifffile\n",
    "                        tifffile.imwrite(dest_image, data_transposed, photometric='rgb')\n",
    "                    except ImportError:\n",
    "                        images_pil = [Image.fromarray(data_transposed[i]) for i in range(4)]\n",
    "                        images_pil[0].save(dest_image, save_all=True, append_images=images_pil[1:], compression='tiff_deflate')\n",
    "                else:\n",
    "                    print(f\"\\nFile not found: {file_name}\")\n",
    "                    error_count += 1\n",
    "                    continue\n",
    "            else:\n",
    "                dest_image = output_images_dir / unique_name\n",
    "                shutil.copy2(source_tiff, dest_image)\n",
    "            label_file = output_labels_dir / unique_name.replace('.tiff', '.txt')\n",
    "            img_annotations = annotations_by_image.get(img_id, [])\n",
    "            with open(label_file, 'w') as f:\n",
    "                for ann in img_annotations:\n",
    "                    category_id = ann['category_id']\n",
    "                    class_id = category_mapping.get(category_id, category_id)\n",
    "                    if 'segmentation' in ann and ann['segmentation']:\n",
    "                        seg_points = convert_coco_segmentation_to_yolo(\n",
    "                            ann['segmentation'], img_width, img_height\n",
    "                        )\n",
    "                        if seg_points:\n",
    "                            points_str = ' '.join([f\"{p:.6f}\" for p in seg_points])\n",
    "                            f.write(f\"{class_id} {points_str}\\n\")\n",
    "                    elif 'bbox' in ann:\n",
    "                        x_c, y_c, w, h = convert_coco_to_yolo_bbox(\n",
    "                            ann['bbox'], img_width, img_height\n",
    "                        )\n",
    "                        f.write(f\"{class_id} {x_c:.6f} {y_c:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "            success_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with {img_info.get('file_name', 'unknown')}: {e}\")\n",
    "            error_count += 1\n",
    "    print(f\"\\nConversion completed:\")\n",
    "    print(f\"   Success: {success_count}\")\n",
    "    print(f\"   Errors: {error_count}\")\n",
    "    return success_count, error_count\n",
    "\n",
    "# Load categories from train JSON\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"CATEGORY ANALYSIS\")\n",
    "print(f\"{'='*80}\")\n",
    "with open(TRAIN_JSON, 'r') as f:\n",
    "    train_coco = json.load(f)\n",
    "categories = train_coco.get('categories', [])\n",
    "print(f\"\\nCategories found: {len(categories)}\")\n",
    "# Create mapping category_id → YOLO class_id (0-indexed)\n",
    "category_mapping = {}\n",
    "category_names = []\n",
    "for i, cat in enumerate(sorted(categories, key=lambda x: x['id'])):\n",
    "    category_mapping[cat['id']] = i\n",
    "    category_names.append(cat['name'])\n",
    "    print(f\"   {cat['id']} → {i}: {cat['name']}\")\n",
    "# Process Train\n",
    "train_input_tiff = TIFF_DATA_DIR / \"train\" / \"images\"\n",
    "train_success, train_errors = process_yolo_split(\n",
    "    train_input_tiff, train_images_dir, train_labels_dir, \n",
    "    TRAIN_JSON, \"train\", category_mapping\n",
    ")\n",
    "# Process Test (as validation in YOLO)\n",
    "test_input_tiff = TIFF_DATA_DIR / \"test\" / \"images\"\n",
    "val_success, val_errors = process_yolo_split(\n",
    "    test_input_tiff, val_images_dir, val_labels_dir,\n",
    "    TEST_JSON, \"val\", category_mapping\n",
    ")\n",
    "# Create dataset.yaml file\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"CREATING DATASET.YAML FILE\")\n",
    "print(f\"{'='*80}\")\n",
    "yaml_content = {\n",
    "    'path': str(YOLO_OUTPUT_DIR.absolute()),\n",
    "    'train': 'train/images',\n",
    "    'val': 'val/images',\n",
    "    'test': 'val/images',  # Use val also for test\n",
    "    'ch': 4,  # 4 channels (BGR + Thermal)\n",
    "    'nc': len(category_names),\n",
    "    'names': category_names\n",
    "}\n",
    "yaml_file = YOLO_OUTPUT_DIR / \"dataset.yaml\"\n",
    "with open(yaml_file, 'w') as f:\n",
    "    yaml.dump(yaml_content, f, default_flow_style=False, sort_keys=False)\n",
    "print(f\"\\nYAML file created: {yaml_file}\")\n",
    "print(f\"\\nContent:\")\n",
    "print(f\"   path: {yaml_content['path']}\")\n",
    "print(f\"   train: {yaml_content['train']}\")\n",
    "print(f\"   val: {yaml_content['val']}\")\n",
    "print(f\"   ch: {yaml_content['ch']} (4 channels: BGR + Thermal)\")\n",
    "print(f\"   nc: {yaml_content['nc']} (classes)\")\n",
    "print(f\"   names: {yaml_content['names']}\")\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nTRAIN:\")\n",
    "print(f\"   Images converted: {train_success}\")\n",
    "print(f\"   Errors: {train_errors}\")\n",
    "print(f\"\\nVAL:\")\n",
    "print(f\"   Images converted: {val_success}\")\n",
    "print(f\"   Errors: {val_errors}\")\n",
    "print(f\"\\nTotal: {train_success + val_success} images\")\n",
    "if train_success + val_success > 0:\n",
    "    print(f\"\\nYOLO dataset created successfully!\")\n",
    "    print(f\"\\nFinal structure:\")\n",
    "    print(f\"   {YOLO_OUTPUT_DIR}/\")\n",
    "    print(f\"   ├── dataset.yaml\")\n",
    "    print(f\"   ├── train/\")\n",
    "    print(f\"   │   ├── images/  ({train_success} TIFF files)\")\n",
    "    print(f\"   │   └── labels/  ({train_success} TXT files)\")\n",
    "    print(f\"   └── val/\")\n",
    "    print(f\"       ├── images/  ({val_success} TIFF files)\")\n",
    "    print(f\"       └── labels/  ({val_success} TXT files)\")\n",
    "    print(f\"\\nConversion completed.\")\n",
    "else:\n",
    "    print(f\"\\nError creating the dataset!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
